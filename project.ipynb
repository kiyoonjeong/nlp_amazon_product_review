{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4ca4485c443143b1888a5fe0ea46464c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e1a9d135678444518927f8539332de4b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9c9730d8141e486db6d866f98abc7faa",
              "IPY_MODEL_68da390a7e8f4dd0988754e32bb1383c"
            ]
          }
        },
        "e1a9d135678444518927f8539332de4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c9730d8141e486db6d866f98abc7faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5980ca9356bc49fdb4a8979b458d59d4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eada75ad32ca42e4b2c6c6991ea4195d"
          }
        },
        "68da390a7e8f4dd0988754e32bb1383c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d457e353fd084769b81c00c538b16b94",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 303kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ce39610d68d4bc9b30e20045589f112"
          }
        },
        "5980ca9356bc49fdb4a8979b458d59d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eada75ad32ca42e4b2c6c6991ea4195d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d457e353fd084769b81c00c538b16b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ce39610d68d4bc9b30e20045589f112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d28b41812d994bf2873c14b4eca3a807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4e871824c38a49f7a6df2dd944d13eb2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e97282460ed6430692892f0cab3b3178",
              "IPY_MODEL_f24de5b61b9048fe86b788976bd50cf7"
            ]
          }
        },
        "4e871824c38a49f7a6df2dd944d13eb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e97282460ed6430692892f0cab3b3178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_687ad98c699140859de149ba3f111625",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64fcba24111a49d68a89a81333727b37"
          }
        },
        "f24de5b61b9048fe86b788976bd50cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b2f77a95f3f24d4bb69bbc8ee0c7c9d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:11&lt;00:00, 38.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57c0d174cb3043a190584a7b3e412a11"
          }
        },
        "687ad98c699140859de149ba3f111625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64fcba24111a49d68a89a81333727b37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2f77a95f3f24d4bb69bbc8ee0c7c9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57c0d174cb3043a190584a7b3e412a11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1ca98ab25b340e7aeebef909c3ffc39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b65b63b7f6494fb19aff9851e17bdd1f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4df972b4843f4785846c6c4660603f29",
              "IPY_MODEL_ae26f9c71b174539962564166c8d9e1b"
            ]
          }
        },
        "b65b63b7f6494fb19aff9851e17bdd1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4df972b4843f4785846c6c4660603f29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1fb7686386ca4d3391060dad6cc2bb2c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d486313ed70f45b1ac3361322cf2c948"
          }
        },
        "ae26f9c71b174539962564166c8d9e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c797bfae4a3409d9c7fd010ceab4033",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 61.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fefe1d52e8664b8283505a71b59be438"
          }
        },
        "1fb7686386ca4d3391060dad6cc2bb2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d486313ed70f45b1ac3361322cf2c948": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c797bfae4a3409d9c7fd010ceab4033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fefe1d52e8664b8283505a71b59be438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad6e72befed2463ebc8a12e5ac2d04b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_79114279630e49d4bc2634110ee348ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c1197b0173a64034bf509a58fde5b941",
              "IPY_MODEL_21ede0a11ccb4bf2b8d3071ae01fe00b"
            ]
          }
        },
        "79114279630e49d4bc2634110ee348ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1197b0173a64034bf509a58fde5b941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_333b843757c343028b1d886e88d0932b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03d6fd4f204b493699b7d7d0fce76f5e"
          }
        },
        "21ede0a11ccb4bf2b8d3071ae01fe00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_405da2830d4f4227a3afd45b260a1770",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [54:49&lt;00:00, 822.45s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08af5290cb15485881d9ba443bc842b3"
          }
        },
        "333b843757c343028b1d886e88d0932b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03d6fd4f204b493699b7d7d0fce76f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "405da2830d4f4227a3afd45b260a1770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08af5290cb15485881d9ba443bc842b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e672e3e777a747ab92751d4d6ef9320d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_24b4e79065e04982b02ac9d13de3dd1e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6dbc131c76c84adb9cbbd66f938b2e0d",
              "IPY_MODEL_f81342f544534654aedfd29ecdcf4282"
            ]
          }
        },
        "24b4e79065e04982b02ac9d13de3dd1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6dbc131c76c84adb9cbbd66f938b2e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_02327bb004c8401d8797cffa40137045",
            "_dom_classes": [],
            "description": "Epoch 1: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 4981,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4981,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51c7dd5f0abf488eb59ad6a6f3caad54"
          }
        },
        "f81342f544534654aedfd29ecdcf4282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6846730c49a84ca4bc4f6dec56a3c156",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4981/4981 [13:24&lt;00:00,  6.82it/s, training_loss=0.349]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0a45638f9304aabae6cba157b5b807e"
          }
        },
        "02327bb004c8401d8797cffa40137045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51c7dd5f0abf488eb59ad6a6f3caad54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6846730c49a84ca4bc4f6dec56a3c156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0a45638f9304aabae6cba157b5b807e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76e78b0719074001a16dc1d362e15142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c994aef1ac0840ba87996d0ad0162821",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3c37ec342863463085b8b4901c455cef",
              "IPY_MODEL_113c62841ec34a5789e90cfb62f4eb98"
            ]
          }
        },
        "c994aef1ac0840ba87996d0ad0162821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c37ec342863463085b8b4901c455cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_59749a27539a4be498b21c62532ef4ee",
            "_dom_classes": [],
            "description": "Epoch 2: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 4981,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4981,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c4d9bd7868b46d1a9bd00202e1625bd"
          }
        },
        "113c62841ec34a5789e90cfb62f4eb98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fdea3d794de548a6b47d638e25007448",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4981/4981 [13:07&lt;00:00,  6.88it/s, training_loss=0.188]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3aa5ed8f93f64a598c1942fc3515e3cc"
          }
        },
        "59749a27539a4be498b21c62532ef4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c4d9bd7868b46d1a9bd00202e1625bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fdea3d794de548a6b47d638e25007448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3aa5ed8f93f64a598c1942fc3515e3cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "803d0728e707404b9248f5e9291e9a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4987ac8e1a864238afdc35b0fc4da012",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dcefb42f47df4da5939cc6667e06def9",
              "IPY_MODEL_bcc6e1d3c70b41f98af9bd8265170d69"
            ]
          }
        },
        "4987ac8e1a864238afdc35b0fc4da012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dcefb42f47df4da5939cc6667e06def9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ff60a80de41748dfa34c14a06645569d",
            "_dom_classes": [],
            "description": "Epoch 3: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 4981,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4981,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e13b036aca1d4d43895a3fa29ddaa008"
          }
        },
        "bcc6e1d3c70b41f98af9bd8265170d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fda2f7a471f148099a03b4189b07751c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4981/4981 [13:01&lt;00:00,  7.02it/s, training_loss=0.254]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf5a5bd4b6264f2f8122cedb0de5bb85"
          }
        },
        "ff60a80de41748dfa34c14a06645569d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e13b036aca1d4d43895a3fa29ddaa008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fda2f7a471f148099a03b4189b07751c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf5a5bd4b6264f2f8122cedb0de5bb85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63aa936076c742e3a86c75c723e93a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_182b0089c3304a18bb87a2db617b380d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f5612f4313f74549b8b485ec5d7a5eaf",
              "IPY_MODEL_c4fc6b9761c748edae204e1460b5b5cb"
            ]
          }
        },
        "182b0089c3304a18bb87a2db617b380d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5612f4313f74549b8b485ec5d7a5eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_98d1aa96f5584c8f8b60f7a7b56ed0d9",
            "_dom_classes": [],
            "description": "Epoch 4: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 4981,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4981,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_39397f3613ab48aeb930fde9a8657d5d"
          }
        },
        "c4fc6b9761c748edae204e1460b5b5cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_423ddb03cbe346c4850af3239ea93f1b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4981/4981 [13:04&lt;00:00,  7.07it/s, training_loss=0.188]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_060f0d04c0d04977bfc09d1033c8cb7d"
          }
        },
        "98d1aa96f5584c8f8b60f7a7b56ed0d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "39397f3613ab48aeb930fde9a8657d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "423ddb03cbe346c4850af3239ea93f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "060f0d04c0d04977bfc09d1033c8cb7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aI_js0vj3bR"
      },
      "source": [
        "# **Part0 : Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB1VV3Hbflw6"
      },
      "source": [
        "# **[Preprocess Dataset]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbOJLizCfs2j"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import sklearn\n",
        "\n",
        "test = open(\"amazon_pet.tsv\", encoding='UTF8')\n",
        "read_tsv = csv.reader(test, delimiter = '\\t')\n",
        "df_temp = []\n",
        "for row in read_tsv:\n",
        "    if len(row) == 15:\n",
        "        df_temp.append(row)\n",
        "        \n",
        "df = pd.DataFrame(df_temp[1:], columns = df_temp[0])\n",
        "\n",
        "df['document'] = df[['review_headline', 'review_body']].agg(' '.join, axis=1)\n",
        "df['document'] = df['document'].apply(lambda x: x.lower())\n",
        "df = df[['document','star_rating']]\n",
        "\n",
        "# Unbalanced Dataset\n",
        "print(df['star_rating'].value_counts())\n",
        "\n",
        "# Multiclass Dataset \n",
        "# Use 150000 data for each label. Total 750000.\n",
        "\n",
        "df1 = df[df['star_rating']=='1']\n",
        "df2 = df[df['star_rating']=='2']\n",
        "df3 = df[df['star_rating']=='3']\n",
        "df4 = df[df['star_rating']=='4']\n",
        "df5 = df[df['star_rating']=='5']\n",
        "\n",
        "df1_s = df1.sample(n=150000, random_state = 1)\n",
        "df2_s = df2.sample(n=150000, random_state = 1)\n",
        "df3_s = df3.sample(n=150000, random_state = 1)\n",
        "df4_s = df4.sample(n=150000, random_state = 1)\n",
        "df5_s = df5.sample(n=150000, random_state = 1)\n",
        "\n",
        "df_final = df1_s.append(df2_s).append(df3_s).append(df4_s).append(df5_s)\n",
        "\n",
        "import re\n",
        "df_final['document'] = df_final['document'].apply(lambda x: ' '.join(re.split(r\"\\W+\", x)))\n",
        "df_final.to_csv('pet.csv', index = False)\n",
        "\n",
        "# Binary Dataset\n",
        "df_bad = df1.append(df2).append(df3)\n",
        "df_good = df4.append(df5)\n",
        "\n",
        "df_bad['star_rating'] = 0 \n",
        "df_good['star_rating'] = 1\n",
        "\n",
        "df_bs = df_bad.sample(n=500000, random_state = 1)\n",
        "df_gs = df_good.sample(n=500000, random_state = 1)\n",
        "\n",
        "new_df = df_bs.append(df_gs)\n",
        "\n",
        "new_df['document'] = new_df['document'].apply(lambda x: ' '.join(re.split(r\"\\W+\", x)))\n",
        "new_df.to_csv('pet2.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGplbyNdjqBl"
      },
      "source": [
        "# **Part1A : ML Multiclass**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj8S4d8jhBho"
      },
      "source": [
        "# **[Count Vector]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzqeGQh4iJkV",
        "outputId": "659ee398-5613-482b-d3f1-f3df5081bbdd"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2MB)\n",
            "\u001b[K     |████████████████████████████████| 204.2MB 64kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 48.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612243 sha256=686b422a013c1384aab11b9e4382a130caf2222a8ab804fbf2cbb51d61b7e4e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/bd/07/031766ca628adec8435bb40f0bd83bb676ce65ff4007f8e73f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQBJGNleiLH1",
        "outputId": "da9ca7b6-f934-4981-c0c3-3e91ed413e9b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDQ8b3mThoZ5",
        "outputId": "d5e7c1cb-f3aa-4138-a5ba-e18caa331183"
      },
      "source": [
        "from pyspark.sql import SQLContext\n",
        "from pyspark import SparkContext\n",
        "sc =SparkContext()\n",
        "sqlContext = SQLContext(sc)\n",
        "data = sqlContext.read.format('csv').options(header='true', inferschema='true').load('pet.csv')\n",
        "data.groupBy(\"star_rating\").count().show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+------+\n",
            "|star_rating| count|\n",
            "+-----------+------+\n",
            "|          1|150000|\n",
            "|          3|150000|\n",
            "|          5|150000|\n",
            "|          4|150000|\n",
            "|          2|150000|\n",
            "+-----------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj0sU9_JhzrA"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "sw = stopwords.words('english')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01Emg0T-iUEu",
        "outputId": "73f29a60-aa2e-45bf-cb84-beba9e5c212d"
      },
      "source": [
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "regexTokenizer = RegexTokenizer(inputCol=\"document\", outputCol=\"words\", pattern=\"\\\\W\")\n",
        "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(sw)\n",
        "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
        "label_stringIdx = StringIndexer(inputCol = \"star_rating\", outputCol = \"label\")\n",
        "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n",
        "# Fit the pipeline to training documents.\n",
        "pipelineFit = pipeline.fit(data)\n",
        "dataset = pipelineFit.transform(data)\n",
        "dataset.show(5)\n",
        "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
        "\n",
        "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
        "lrModel = lr.fit(trainingData)\n",
        "predictions = lrModel.transform(testData)\n",
        "\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----------+--------------------+--------------------+--------------------+-----+\n",
            "|            document|star_rating|               words|            filtered|            features|label|\n",
            "+--------------------+-----------+--------------------+--------------------+--------------------+-----+\n",
            "|your cat will go ...|          1|[your, cat, will,...|[cat, go, hunter,...|(10000,[3,7,12,13...|  0.0|\n",
            "|two stars stopped...|          1|[two, stars, stop...|[two, stars, stop...|(10000,[14,17,27,...|  0.0|\n",
            "| worked for a tot...|          1|[worked, for, a, ...|[worked, total, t...|(10000,[1,16,17,5...|  0.0|\n",
            "|not the best qual...|          1|[not, the, best, ...|[best, quality, p...|(10000,[0,1,50,51...|  0.0|\n",
            "|one star cats hat...|          1|[one, star, cats,...|[one, star, cats,...|(10000,[2,5,12,38...|  0.0|\n",
            "+--------------------+-----------+--------------------+--------------------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5790502527468073"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HgfKD3PjMvQ",
        "outputId": "de41b133-818e-4de0-f39b-056eff5b8b78"
      },
      "source": [
        "predictions.select(\"label\",\"prediction\") \\\n",
        "    .groupBy(\"label\",\"prediction\") \\\n",
        "    .count() \\\n",
        "    .show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  2.0|       0.0| 3848|\n",
            "|  1.0|       1.0|20856|\n",
            "|  3.0|       2.0| 6501|\n",
            "|  4.0|       2.0| 1595|\n",
            "|  0.0|       1.0| 8531|\n",
            "|  0.0|       4.0| 1428|\n",
            "|  1.0|       0.0|10768|\n",
            "|  2.0|       2.0|20981|\n",
            "|  3.0|       1.0| 2723|\n",
            "|  2.0|       3.0| 7613|\n",
            "|  1.0|       4.0| 2230|\n",
            "|  4.0|       4.0|35124|\n",
            "|  2.0|       4.0| 3609|\n",
            "|  3.0|       4.0|11040|\n",
            "|  2.0|       1.0| 8931|\n",
            "|  1.0|       2.0| 8374|\n",
            "|  0.0|       0.0|31625|\n",
            "|  1.0|       3.0| 2899|\n",
            "|  4.0|       3.0| 6330|\n",
            "|  0.0|       2.0| 2473|\n",
            "+-----+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw4p9m4VhopT"
      },
      "source": [
        "# **[TF-IDF]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW0kcDZDiUHw",
        "outputId": "21a66400-a89c-4c73-bfc0-8670b4dcc991"
      },
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
        "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])\n",
        "pipelineFit = pipeline.fit(data)\n",
        "dataset = pipelineFit.transform(data)\n",
        "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
        "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
        "lrModel = lr.fit(trainingData)\n",
        "predictions = lrModel.transform(testData)\n",
        "predictions.filter(predictions['prediction'] == 0) \\\n",
        "    .select(\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------+-----+----------+\n",
            "|                   probability|label|prediction|\n",
            "+------------------------------+-----+----------+\n",
            "|[0.9999999985436254,1.44708...|  0.0|       0.0|\n",
            "|[0.9999997422210548,1.85806...|  0.0|       0.0|\n",
            "|[0.9999990732413198,9.23504...|  0.0|       0.0|\n",
            "|[0.9999958147123547,4.08301...|  0.0|       0.0|\n",
            "|[0.999990144378054,9.680507...|  0.0|       0.0|\n",
            "|[0.9999839093117626,4.11381...|  0.0|       0.0|\n",
            "|[0.9999813933323186,1.82980...|  0.0|       0.0|\n",
            "|[0.9999563452526603,1.91689...|  0.0|       0.0|\n",
            "|[0.9999550744570272,4.40600...|  0.0|       0.0|\n",
            "|[0.9999214457712443,4.05804...|  0.0|       0.0|\n",
            "+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5668025763990974"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BvU4k_GiULd",
        "outputId": "99af2ff1-e313-42a0-cf90-33067c2f3ae4"
      },
      "source": [
        "predictions.select(\"label\",\"prediction\") \\\n",
        "    .groupBy(\"label\",\"prediction\") \\\n",
        "    .count() \\\n",
        "    .show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  2.0|       0.0| 4099|\n",
            "|  1.0|       1.0|20154|\n",
            "|  3.0|       2.0| 6485|\n",
            "|  4.0|       2.0| 1754|\n",
            "|  0.0|       1.0| 8320|\n",
            "|  0.0|       4.0| 1797|\n",
            "|  1.0|       0.0|11008|\n",
            "|  2.0|       2.0|20525|\n",
            "|  3.0|       1.0| 2865|\n",
            "|  2.0|       3.0| 7380|\n",
            "|  1.0|       4.0| 2858|\n",
            "|  4.0|       4.0|34787|\n",
            "|  2.0|       4.0| 4141|\n",
            "|  3.0|       4.0|11409|\n",
            "|  2.0|       1.0| 8837|\n",
            "|  1.0|       2.0| 8180|\n",
            "|  0.0|       0.0|31281|\n",
            "|  1.0|       3.0| 2927|\n",
            "|  4.0|       3.0| 6116|\n",
            "|  0.0|       2.0| 2570|\n",
            "+-----+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugZid57ohpZH"
      },
      "source": [
        "# **[Naive Bayes]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92aEhA_djUDq",
        "outputId": "1cecf72d-6ded-40c8-c2f9-b283ab8c0c5e"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "nb = NaiveBayes(smoothing=1)\n",
        "model = nb.fit(trainingData)\n",
        "predictions = model.transform(testData)\n",
        "predictions.filter(predictions['prediction'] == 0) \\\n",
        "    .select(\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------+-----+----------+\n",
            "|                   probability|label|prediction|\n",
            "+------------------------------+-----+----------+\n",
            "|[1.0,1.1006000566979454E-16...|  0.0|       0.0|\n",
            "|[1.0,1.0904563018103447E-16...|  0.0|       0.0|\n",
            "|[1.0,1.0824173581298883E-16...|  0.0|       0.0|\n",
            "|[1.0,1.0765016333084843E-16...|  0.0|       0.0|\n",
            "|[1.0,1.06385762059194E-16,9...|  0.0|       0.0|\n",
            "|[1.0,1.0607994902226649E-16...|  0.0|       0.0|\n",
            "|[1.0,1.0559923722345248E-16...|  0.0|       0.0|\n",
            "|[1.0,1.0552316304675009E-16...|  0.0|       0.0|\n",
            "|[1.0,1.0548079285995357E-16...|  2.0|       0.0|\n",
            "|[1.0,1.0408637469940159E-16...|  0.0|       0.0|\n",
            "+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5260304663587719"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX2ccH1zjX8X",
        "outputId": "f9323b61-31bb-4890-81d3-99dbdd3b505f"
      },
      "source": [
        "predictions.select(\"label\",\"prediction\") \\\n",
        "    .groupBy(\"label\",\"prediction\") \\\n",
        "    .count() \\\n",
        "    .show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  2.0|       0.0| 4307|\n",
            "|  1.0|       1.0|17953|\n",
            "|  3.0|       2.0| 7424|\n",
            "|  4.0|       2.0| 2089|\n",
            "|  0.0|       1.0| 9905|\n",
            "|  0.0|       4.0| 2136|\n",
            "|  1.0|       0.0| 9456|\n",
            "|  2.0|       2.0|20096|\n",
            "|  3.0|       1.0| 2852|\n",
            "|  2.0|       3.0| 7568|\n",
            "|  1.0|       4.0| 4072|\n",
            "|  4.0|       4.0|32850|\n",
            "|  2.0|       4.0| 5140|\n",
            "|  3.0|       4.0|11717|\n",
            "|  2.0|       1.0| 7871|\n",
            "|  1.0|       2.0| 9873|\n",
            "|  0.0|       0.0|27954|\n",
            "|  1.0|       3.0| 3773|\n",
            "|  4.0|       3.0| 7223|\n",
            "|  0.0|       2.0| 3429|\n",
            "+-----+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNqsKA4EkHKJ"
      },
      "source": [
        "# **Part1B : ML Binary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY_QthJ-ln7p"
      },
      "source": [
        "# **[Count Vector]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6wUZ-9dkrmu"
      },
      "source": [
        "from pyspark.sql import SQLContext\n",
        "from pyspark import SparkContext\n",
        "sc =SparkContext()\n",
        "sqlContext = SQLContext(sc)\n",
        "data = sqlContext.read.format('csv').options(header='true', inferschema='true').load('pet2.csv')\n",
        "data.groupBy(\"star_rating\").count().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znoaba8XlVom"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "sw = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUNBwXz7la1_"
      },
      "source": [
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "regexTokenizer = RegexTokenizer(inputCol=\"document\", outputCol=\"words\", pattern=\"\\\\W\")\n",
        "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(sw)\n",
        "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
        "label_stringIdx = StringIndexer(inputCol = \"star_rating\", outputCol = \"label\")\n",
        "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n",
        "# Fit the pipeline to training documents.\n",
        "pipelineFit = pipeline.fit(data)\n",
        "dataset = pipelineFit.transform(data)\n",
        "dataset.show(5)\n",
        "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
        "\n",
        "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
        "lrModel = lr.fit(trainingData)\n",
        "predictions = lrModel.transform(testData)\n",
        "\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jysLmyUTlfkl"
      },
      "source": [
        "predictions.select(\"label\",\"prediction\") \\\n",
        "    .groupBy(\"label\",\"prediction\") \\\n",
        "    .count() \\\n",
        "    .show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weRlBVyfl0NE"
      },
      "source": [
        "# **[TF-IDF]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o2CSkcmljZ1"
      },
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
        "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])\n",
        "pipelineFit = pipeline.fit(data)\n",
        "dataset = pipelineFit.transform(data)\n",
        "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
        "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
        "lrModel = lr.fit(trainingData)\n",
        "predictions = lrModel.transform(testData)\n",
        "predictions.filter(predictions['prediction'] == 0) \\\n",
        "    .select(\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HM7vL1qljcZ"
      },
      "source": [
        "predictions.select(\"label\",\"prediction\") \\\n",
        "    .groupBy(\"label\",\"prediction\") \\\n",
        "    .count() \\\n",
        "    .show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxAXkxCvl6XU"
      },
      "source": [
        "# **[Naive Bayes]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OZLld9EljfO"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "nb = NaiveBayes(smoothing=1)\n",
        "model = nb.fit(trainingData)\n",
        "predictions = model.transform(testData)\n",
        "predictions.filter(predictions['prediction'] == 0) \\\n",
        "    .select(\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHkYSiIFljh4"
      },
      "source": [
        "predictions.select(\"label\",\"prediction\") \\\n",
        "    .groupBy(\"label\",\"prediction\") \\\n",
        "    .count() \\\n",
        "    .show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lD0FhtAlBSW"
      },
      "source": [
        "# **Part2 : DeepLearning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKX2QVEse3MN"
      },
      "source": [
        "# **[BERT Binary]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C3WpN-51d-z"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W-dw_UTjUgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8bb5656-6385-4f28-af8b-ef5a186aa967"
      },
      "source": [
        "if torch.cuda.is_available():   \n",
        "   device = torch.device(\"cuda\")\n",
        "   print('Using GPU ', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "   device = torch.device(\"cpu\")\n",
        "   print('Using CPU')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU  Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXj71MRAjdXv"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhXWTs-4jjX0"
      },
      "source": [
        "from transformers import BertTokenizer, AdamW, BertForSequenceClassification\n",
        " \n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels = 2, return_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMOxjVonhh66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "21128e67-b40a-46f5-d65e-c24a7438b6af"
      },
      "source": [
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-56b31908e0b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGDVqXwC8P6G"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, precision_recall_fscore_support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2aNj3GNMl5K"
      },
      "source": [
        "import pandas as pd\n",
        "df_pet = pd.read_csv('pet2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QELct3FKhgKW",
        "outputId": "f1ebc79a-df58-4913-a41d-bb62ae007513"
      },
      "source": [
        "print(df_pet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 document  star_rating\n",
            "0       your cat will go from being the hunter to the ...            1\n",
            "1                    two stars stopped working in 2 weeks            1\n",
            "2        worked for a total of two weeks what a waste ...            1\n",
            "3       not the best quality pros very easy to assembl...            1\n",
            "4       one star cats hated it it was noisy they did n...            1\n",
            "...                                                   ...          ...\n",
            "749995  quick and easy to use i got this based on all ...            5\n",
            "749996  perfect i bought the large for my pug and fren...            5\n",
            "749997  perfect well made and just what i needed perfe...            5\n",
            "749998  cats meow great toy that the cat loves playing...            5\n",
            "749999  perfect for a small dog i have a 5lb maltese a...            5\n",
            "\n",
            "[750000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISRfH95ecdY_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#Use 25% of Dataset\n",
        "df_dataset, df_75 = train_test_split(df_pet, test_size=0.75, shuffle=True)\n",
        "\n",
        "#Train/Test\n",
        "df_train, df_test = train_test_split(df_dataset, test_size=0.25, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC9JFewsOlHy",
        "outputId": "69a2753e-a9db-49ab-91d5-5926ddf17cc0"
      },
      "source": [
        "# Training - print F1 score every epoch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "softmax_fn = torch.nn.Softmax(dim=1) # this returns a function that does softmax\n",
        "from transformers import AdamW\n",
        "from torch.nn import functional as F\n",
        "\n",
        "epochs = 4\n",
        "early_stop_epochs = 4\n",
        "k = 1\n",
        "each_len = len(df_train)//5\n",
        "x_df = list(df_train['document'])\n",
        "y_df = list(df_train['star_rating'])\n",
        "\n",
        "# Test Set\n",
        "x_test = list(df_test['document'])\n",
        "y_test = list(df_test['star_rating'])\n",
        "\n",
        "sentences = x_test\n",
        "labels = y_test\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "batch_size = 32  \n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "\n",
        "# Main loop\n",
        "lr = 0.00001\n",
        "for i in range(k):\n",
        "    print(\"k : \" , i)\n",
        "    x_test = x_df[each_len*i:each_len*(i+1)]\n",
        "    x_train = x_df[:each_len*i]+x_df[each_len*(i+1):]\n",
        "    y_test = y_df[each_len*i:each_len*(i+1)]\n",
        "    y_train = y_df[:each_len*i]+y_df[each_len*(i+1):]\n",
        "\n",
        "    # DataLoader\n",
        "    batch_size = 32\n",
        "    train_dataset = [[x_train[i], y_train[i]] for i in range(len(x_train))]\n",
        "    test_dataset = [[x_test[i], y_test[i]] for i in range(len(x_test))]\n",
        "    train_loader = DataLoader(dataset=train_dataset,sampler = RandomSampler(train_dataset), batch_size=batch_size)\n",
        "    test_loader = DataLoader(dataset=test_dataset,sampler = SequentialSampler(test_dataset), batch_size=batch_size)\n",
        "\n",
        "    # Model\n",
        "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels = 2, return_dict=True)\n",
        "    model.cuda()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    #scheduler\n",
        "    total_steps = len(train_loader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "    nondecreasing = 0\n",
        "    prev_loss = 9999999\n",
        "    for epoch in range(epochs):  \n",
        "        print(\"epoch : \" , epoch)   \n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for [batch_x, batch_y] in train_loader:\n",
        "            encoding = tokenizer(list(batch_x), return_tensors='pt',max_length = 64, padding=True, truncation=True)\n",
        "            input_ids = encoding['input_ids'].to(device)\n",
        "            attention_mask = encoding['attention_mask'].to(device)\n",
        "            labels = torch.tensor(batch_y).to(device)\n",
        "            model.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            softmax_fn = torch.nn.Softmax(dim=1)\n",
        "            softmaxed_output = softmax_fn(outputs.logits)\n",
        "            loss = F.cross_entropy(softmaxed_output, labels)\n",
        "            total_loss += loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        print(\"  avg_train_loss : {0:.2f}\".format(avg_train_loss))\n",
        "        model.eval()\n",
        "        total_eval_loss = 0\n",
        "\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for [batch_x,batch_y] in test_loader:            \n",
        "            encoding = tokenizer(list(batch_x), return_tensors='pt',max_length = 64, padding=True, truncation=True)\n",
        "            input_ids = encoding['input_ids'].to(device)\n",
        "            attention_mask = encoding['attention_mask'].to(device)\n",
        "            labels = torch.tensor(batch_y).to(device)\n",
        "\n",
        "            with torch.no_grad():        \n",
        "                outputs = model(input_ids, \n",
        "                                      token_type_ids=None, \n",
        "                                      attention_mask=attention_mask,\n",
        "                                      labels=labels)\n",
        "                softmax_fn = torch.nn.Softmax(dim=1)\n",
        "                softmaxed_output = softmax_fn(outputs.logits)\n",
        "                loss = F.cross_entropy(softmaxed_output, labels)\n",
        "                total_eval_loss += loss\n",
        "                \n",
        "            # Accumulate the validation loss.\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_val_loss = total_eval_loss / len(test_loader)\n",
        "        \n",
        "        print(\"  avg_val_loss : {0:.2f}\".format(avg_val_loss))\n",
        "\n",
        "        # check total loss\n",
        "        if prev_loss - total_eval_loss <= 1e-5:\n",
        "            nondecreasing += 1\n",
        "        else:\n",
        "            nondecreasing = 0\n",
        "        \n",
        "        if nondecreasing >= early_stop_epochs:\n",
        "            break\n",
        "            \n",
        "        prev_loss = total_eval_loss\n",
        "\n",
        "    #Test\n",
        "    model.eval()\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in prediction_dataloader:\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      b_input_ids, b_input_mask, b_labels = batch\n",
        "      with torch.no_grad():\n",
        "          outputs = model(b_input_ids, token_type_ids=None, \n",
        "                          attention_mask=b_input_mask)\n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "      for [el1, el2] in logits:\n",
        "        if el1 < el2:\n",
        "          predictions.append(1)\n",
        "        else:\n",
        "          predictions.append(0)\n",
        "      for element in label_ids:\n",
        "        true_labels.append(element)\n",
        "    predictions = np.array(predictions)\n",
        "    true_labels = np.array(true_labels)\n",
        "\n",
        "    print(precision_recall_fscore_support(true_labels,predictions, average= 'micro'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "k :  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch :  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  avg_train_loss : 0.39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:108: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  avg_val_loss : 0.75\n",
            "epoch :  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZGzNSYAhkRi"
      },
      "source": [
        "# Training - print F1 score every epoch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "softmax_fn = torch.nn.Softmax(dim=1) # this returns a function that does softmax\n",
        "from transformers import AdamW\n",
        "from torch.nn import functional as F\n",
        "\n",
        "epochs = 4\n",
        "early_stop_epochs = 4\n",
        "\n",
        "\n",
        "k = 1\n",
        "each_len = len(df_train)//5\n",
        "x_df = list(df_train['document'])\n",
        "y_df = list(df_train['star_rating'])\n",
        "\n",
        "x_test = list(df_test['document'])\n",
        "y_test = list(df_test['star_rating'])\n",
        "\n",
        "sentences = x_test\n",
        "labels = y_test\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "batch_size = 32  \n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "\n",
        "# Main loop\n",
        "lr = 0.00001\n",
        "print(\"k : \" , i)\n",
        "#Validation Set\n",
        "x_test = x_df[each_len*i:each_len*(i+1)]\n",
        "x_train = x_df[:each_len*i]+x_df[each_len*(i+1):]\n",
        "y_test = y_df[each_len*i:each_len*(i+1)]\n",
        "y_train = y_df[:each_len*i]+y_df[each_len*(i+1):]\n",
        "\n",
        "# DataLoader\n",
        "batch_size = 32\n",
        "train_dataset = [[x_train[i], y_train[i]] for i in range(len(x_train))]\n",
        "test_dataset = [[x_test[i], y_test[i]] for i in range(len(x_test))]\n",
        "train_loader = DataLoader(dataset=train_dataset,sampler = RandomSampler(train_dataset), batch_size=batch_size)\n",
        "test_loader = DataLoader(dataset=test_dataset,sampler = SequentialSampler(test_dataset), batch_size=batch_size)\n",
        "\n",
        "# Model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels = 5, return_dict=True)\n",
        "model.cuda()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "#scheduler\n",
        "total_steps = len(train_loader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                        num_warmup_steps = 0,\n",
        "                                        num_training_steps = total_steps)\n",
        "\n",
        "nondecreasing = 0\n",
        "prev_loss = 9999999\n",
        "for epoch in range(epochs):  \n",
        "    print(\"epoch : \" , epoch)   \n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for [batch_x, batch_y] in train_loader:\n",
        "        encoding = tokenizer(list(batch_x), return_tensors='pt',max_length = 64, padding=True, truncation=True)\n",
        "        input_ids = encoding['input_ids'].to(device)\n",
        "        attention_mask = encoding['attention_mask'].to(device)\n",
        "        labels = torch.tensor(batch_y).to(device)\n",
        "        model.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        softmax_fn = torch.nn.Softmax(dim=1)\n",
        "        softmaxed_output = softmax_fn(outputs.logits)\n",
        "        loss = F.cross_entropy(softmaxed_output, labels)\n",
        "        total_loss += loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    print(\"  avg_train_loss : {0:.2f}\".format(avg_train_loss))\n",
        "    model.eval()\n",
        "    total_eval_loss = 0\n",
        "\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for [batch_x,batch_y] in test_loader:            \n",
        "        encoding = tokenizer(list(batch_x), return_tensors='pt',max_length = 64, padding=True, truncation=True)\n",
        "        input_ids = encoding['input_ids'].to(device)\n",
        "        attention_mask = encoding['attention_mask'].to(device)\n",
        "        labels = torch.tensor(batch_y).to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(input_ids, \n",
        "                                  token_type_ids=None, \n",
        "                                  attention_mask=attention_mask,\n",
        "                                  labels=labels)\n",
        "            softmax_fn = torch.nn.Softmax(dim=1)\n",
        "            softmaxed_output = softmax_fn(outputs.logits)\n",
        "            loss = F.cross_entropy(softmaxed_output, labels)\n",
        "            total_eval_loss += loss\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(test_loader)\n",
        "    \n",
        "    print(\"  avg_val_loss : {0:.2f}\".format(avg_val_loss))\n",
        "\n",
        "    # check total loss\n",
        "    if prev_loss - total_eval_loss <= 1e-5:\n",
        "        nondecreasing += 1\n",
        "    else:\n",
        "        nondecreasing = 0\n",
        "    \n",
        "    if nondecreasing >= early_stop_epochs:\n",
        "        break\n",
        "        \n",
        "    prev_loss = total_eval_loss\n",
        "\n",
        "#Test\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "  logits = outputs[0]\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  for [el1, el2] in logits:\n",
        "    if el1 < el2:\n",
        "      predictions.append(1)\n",
        "    else:\n",
        "      predictions.append(0)\n",
        "  for element in label_ids:\n",
        "    true_labels.append(element)\n",
        "predictions = np.array(predictions)\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "print(precision_recall_fscore_support(true_labels,predictions, average= 'micro'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-p4m1GefNnX"
      },
      "source": [
        "# **[BERT Mulitclass]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaUfy_zXilgy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "7b1ee752-34bd-4d92-e401-94ed73c584ae"
      },
      "source": [
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-01c38c35c13d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZv00mxO5S_S"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('pet.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3x4Qlqy5gy6",
        "outputId": "177a3635-89f5-449a-8f80-61fdac2510ad"
      },
      "source": [
        "possible_labels = df.star_rating.unique()\n",
        "\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2uQrapL6HIJ"
      },
      "source": [
        "df['label'] = df.star_rating.replace(label_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh2Ntg6tjzKK"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df, df_75 = train_test_split(df, test_size=0.75, shuffle=True)\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
        "                                                  df.label.values, \n",
        "                                                  test_size=0.15, \n",
        "                                                  random_state=42, \n",
        "                                                  stratify=df.label.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RXkNT1UkgJx"
      },
      "source": [
        "df['data_type'] = ['not_set']*df.shape[0]\n",
        "\n",
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zQKff2Bk-NS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "4ca4485c443143b1888a5fe0ea46464c",
            "e1a9d135678444518927f8539332de4b",
            "9c9730d8141e486db6d866f98abc7faa",
            "68da390a7e8f4dd0988754e32bb1383c",
            "5980ca9356bc49fdb4a8979b458d59d4",
            "eada75ad32ca42e4b2c6c6991ea4195d",
            "d457e353fd084769b81c00c538b16b94",
            "0ce39610d68d4bc9b30e20045589f112"
          ]
        },
        "outputId": "c9e5e9af-e27d-4d0e-c0b3-2c4e54146569"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
        "                                          do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ca4485c443143b1888a5fe0ea46464c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPp4oqZ_k-FI",
        "outputId": "cf48b7fa-0f97-4d88-84ce-759f563399e6"
      },
      "source": [
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='train'].document.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=64, \n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='val'].document.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=64, \n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpjyNfOdk-IN"
      },
      "source": [
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "d28b41812d994bf2873c14b4eca3a807",
            "4e871824c38a49f7a6df2dd944d13eb2",
            "e97282460ed6430692892f0cab3b3178",
            "f24de5b61b9048fe86b788976bd50cf7",
            "687ad98c699140859de149ba3f111625",
            "64fcba24111a49d68a89a81333727b37",
            "b2f77a95f3f24d4bb69bbc8ee0c7c9d2",
            "57c0d174cb3043a190584a7b3e412a11",
            "b1ca98ab25b340e7aeebef909c3ffc39",
            "b65b63b7f6494fb19aff9851e17bdd1f",
            "4df972b4843f4785846c6c4660603f29",
            "ae26f9c71b174539962564166c8d9e1b",
            "1fb7686386ca4d3391060dad6cc2bb2c",
            "d486313ed70f45b1ac3361322cf2c948",
            "0c797bfae4a3409d9c7fd010ceab4033",
            "fefe1d52e8664b8283505a71b59be438"
          ]
        },
        "id": "SY2kChpC7YOw",
        "outputId": "6232c73c-3bbb-497b-ba28-f5defbcc6fae"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                      num_labels=len(label_dict),\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d28b41812d994bf2873c14b4eca3a807",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1ca98ab25b340e7aeebef909c3ffc39",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0dFVmO0k-P4"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, \n",
        "                              sampler=RandomSampler(dataset_train), \n",
        "                              batch_size=batch_size)\n",
        "\n",
        "dataloader_validation = DataLoader(dataset_val, \n",
        "                                   sampler=SequentialSampler(dataset_val), \n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk4JpDNjmZv4"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=1e-5, \n",
        "                  eps=1e-8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoNyD4SxmZye"
      },
      "source": [
        "epochs = 4\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=len(dataloader_train)*epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR77-GIhmZ07"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "399zWOW8mZ3g"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7k2XXPI7xGt",
        "outputId": "4de4c915-7b7b-4caf-8921-fd44749111e4"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM5Gu39EnqUX"
      },
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in dataloader_val:\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406,
          "referenced_widgets": [
            "ad6e72befed2463ebc8a12e5ac2d04b8",
            "79114279630e49d4bc2634110ee348ba",
            "c1197b0173a64034bf509a58fde5b941",
            "21ede0a11ccb4bf2b8d3071ae01fe00b",
            "333b843757c343028b1d886e88d0932b",
            "03d6fd4f204b493699b7d7d0fce76f5e",
            "405da2830d4f4227a3afd45b260a1770",
            "08af5290cb15485881d9ba443bc842b3",
            "e672e3e777a747ab92751d4d6ef9320d",
            "24b4e79065e04982b02ac9d13de3dd1e",
            "6dbc131c76c84adb9cbbd66f938b2e0d",
            "f81342f544534654aedfd29ecdcf4282",
            "02327bb004c8401d8797cffa40137045",
            "51c7dd5f0abf488eb59ad6a6f3caad54",
            "6846730c49a84ca4bc4f6dec56a3c156",
            "c0a45638f9304aabae6cba157b5b807e",
            "76e78b0719074001a16dc1d362e15142",
            "c994aef1ac0840ba87996d0ad0162821",
            "3c37ec342863463085b8b4901c455cef",
            "113c62841ec34a5789e90cfb62f4eb98",
            "59749a27539a4be498b21c62532ef4ee",
            "3c4d9bd7868b46d1a9bd00202e1625bd",
            "fdea3d794de548a6b47d638e25007448",
            "3aa5ed8f93f64a598c1942fc3515e3cc",
            "803d0728e707404b9248f5e9291e9a91",
            "4987ac8e1a864238afdc35b0fc4da012",
            "dcefb42f47df4da5939cc6667e06def9",
            "bcc6e1d3c70b41f98af9bd8265170d69",
            "ff60a80de41748dfa34c14a06645569d",
            "e13b036aca1d4d43895a3fa29ddaa008",
            "fda2f7a471f148099a03b4189b07751c",
            "cf5a5bd4b6264f2f8122cedb0de5bb85",
            "63aa936076c742e3a86c75c723e93a9b",
            "182b0089c3304a18bb87a2db617b380d",
            "f5612f4313f74549b8b485ec5d7a5eaf",
            "c4fc6b9761c748edae204e1460b5b5cb",
            "98d1aa96f5584c8f8b60f7a7b56ed0d9",
            "39397f3613ab48aeb930fde9a8657d5d",
            "423ddb03cbe346c4850af3239ea93f1b",
            "060f0d04c0d04977bfc09d1033c8cb7d"
          ]
        },
        "id": "xsIJbA5poKrb",
        "outputId": "7cac2be6-dccb-446d-c01c-bf6f795a60fa"
      },
      "source": [
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        model.zero_grad()\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }       \n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "         \n",
        "        \n",
        "    torch.save(model.state_dict(), 'checkpoint.pth')\n",
        "        \n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad6e72befed2463ebc8a12e5ac2d04b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e672e3e777a747ab92751d4d6ef9320d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=4981.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Epoch 1\n",
            "Training loss: 0.8609638920487995\n",
            "Validation loss: 0.7809061852195835\n",
            "F1 Score (Weighted): 0.654710136231064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76e78b0719074001a16dc1d362e15142",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=4981.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Epoch 2\n",
            "Training loss: 0.7415518051552212\n",
            "Validation loss: 0.7807751192167758\n",
            "F1 Score (Weighted): 0.6600894124244732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "803d0728e707404b9248f5e9291e9a91",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 3', max=4981.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Epoch 3\n",
            "Training loss: 0.6788264232224142\n",
            "Validation loss: 0.788721758723937\n",
            "F1 Score (Weighted): 0.6608015313999952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63aa936076c742e3a86c75c723e93a9b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 4', max=4981.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Epoch 4\n",
            "Training loss: 0.6333755746714156\n",
            "Validation loss: 0.8135544130826566\n",
            "F1 Score (Weighted): 0.6599681782349686\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LSYxLeZ8V3j",
        "outputId": "c097b699-96ac-4bc0-d102-ea0468e7f359"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                      num_labels=len(label_dict),\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg_qbeUDoKuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d87c270-51f1-41b3-a6f2-ceb340a2da83"
      },
      "source": [
        "model.load_state_dict(torch.load('checkpoint.pth', map_location=torch.device('cpu')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Liapjr79oKw9"
      },
      "source": [
        "_, predictions, true_vals = evaluate(dataloader_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdmImGUxnqXk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c629746f-8a6a-441b-e8a5-9d08c5611d80"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: 1\n",
            "Accuracy: 3958/5640\n",
            "\n",
            "Class: 2\n",
            "Accuracy: 3227/5614\n",
            "\n",
            "Class: 3\n",
            "Accuracy: 3417/5619\n",
            "\n",
            "Class: 4\n",
            "Accuracy: 3385/5592\n",
            "\n",
            "Class: 5\n",
            "Accuracy: 4583/5660\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1OiNSIh8hsN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bNK8tzAngh4"
      },
      "source": [
        "# **Part3 : Important words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I0YQDLhjWHD"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tv = TfidfVectorizer(stop_words = 'english', min_df = 100)\n",
        "tfs = tv.fit_transform(df['document'])\n",
        "feature_names = tv.get_feature_names()\n",
        "test = \" \".join(feature_names)\n",
        "response = tv.transform([test])\n",
        "feature_array = np.array(feature_names)\n",
        "tfidf_sorting = np.argsort(response.toarray()).flatten()[::-1]\n",
        "n = 100\n",
        "top_n = feature_array[tfidf_sorting][:n]\n",
        "print(top_n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n3cB4ERpGC4",
        "outputId": "f75cd932-d992-45da-b2d3-368e452cfb73"
      },
      "source": [
        "for i in range(5):\n",
        "  tv = TfidfVectorizer(stop_words = 'english', min_df = 100)\n",
        "  df_label = df[df['star_rating']==i+1]\n",
        "  tfs = tv.fit_transform(df_label['document'])\n",
        "  feature_names = tv.get_feature_names()\n",
        "  test = \" \".join(feature_names)\n",
        "  response = tv.transform([test])\n",
        "  feature_array = np.array(feature_names)\n",
        "  tfidf_sorting = np.argsort(response.toarray()).flatten()[::-1]\n",
        "  n = 100\n",
        "  top_n = feature_array[tfidf_sorting][:n]\n",
        "  print(top_n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['glued' 'dimensions' 'crack' 'corners' 'stronger' 'raw' 'passed'\n",
            " 'willing' 'obvious' 'beef' 'assembled' 'manual' 'video' 'removing'\n",
            " 'refill' 'measured' 'wild' 'beautiful' 'ad' 'lowest' 'stitching' 'stiff'\n",
            " 'stain' 'bully' 'harder' '2014' 'blade' 'wrap' 'bills' 'tall' 'kids'\n",
            " 'reviewer' 'oz' 'print' 'temp' 'arrive' 'cleaner' 'wrapped' 'son'\n",
            " 'ruined' 'rice' 'clasp' 'posted' 'numerous' 'shop' 'page' 'pig' 'hook'\n",
            " 'tanks' 'current' 'fat' 'sealed' 'burn' 'lightweight' 'bend' 'durability'\n",
            " 'follow' 'outdoor' 'kibble' 'string' 'types' 'grain' 'vibrate' 'english'\n",
            " 'duck' 'tug' 'guinea' 'heart' 'shelf' 'indestructible' 'asking' 'choke'\n",
            " 'refuse' 'tossed' 'directed' 'advise' 'instantly' 'amazing' 'worry'\n",
            " 'feature' 'sat' 'applying' 'colors' 'vibration' 'crappy' 'danger' '17'\n",
            " 'lethargic' 'kitchen' 'covers' 'butter' 'talking' 'refunded' 'terribly'\n",
            " 'beds' 'smelling' 'duty' 'vets' 'writing' 'recent']\n",
            "['miss' 'inexpensive' 'supplement' 'lick' 'appropriate' 'attachment'\n",
            " 'mice' 'fetch' 'outer' 'pillow' 'rawhide' 'offer' 'ramp' 'gross'\n",
            " 'incredibly' 'defeats' 'spaniel' 'measure' 'pushed' 'american' 'tips'\n",
            " 'thinner' 'butter' 'stretch' 'strange' 'improved' 'tends' '3rd' 'trained'\n",
            " 'attractive' 'swallow' 'shorter' 'ask' 'shelf' 'continues' 'unlike'\n",
            " 'grown' 'sewn' 'stainless' 'refuses' 'eh' 'vacuum' 'bummer' 'ticks'\n",
            " 'reasons' 'sucks' 'dose' 'answer' 'contains' 'killed' 'limited' 'general'\n",
            " 'adjusted' 'prefers' 'applied' 'wears' 'scratches' 'stable' 'sleeping'\n",
            " 'phone' 'tighten' 'sale' 'heavier' 'peanut' 'scratched' 'reaction'\n",
            " 'worthless' 'chose' 'exchange' 'execution' 'pen' 'convenient' 'loop'\n",
            " 'specifically' 'meat' 'storage' 'following' 'dusty' 'worried' 'boston'\n",
            " 'waterproof' 'choking' 'required' 'contain' 'belt' 'comfort' 'pug' 'ship'\n",
            " 'term' 'meal' 'tabs' 'betta' 'cap' 'plush' 'pricey' 'according' 'hazard'\n",
            " 'dachshund' 'laying' 'charged']\n",
            "['dig' 'reviewer' 'scratched' 'humans' 'fancy' 'screen' 'treatment'\n",
            " 'everyday' 'suitable' 'reaction' 'flap' 'refused' 'vs' 'offer' 'rock'\n",
            " 'pro' 'begin' 'seams' 'chunks' 'worn' 'clasp' 'pass' '35' 'interesting'\n",
            " 'towel' 'hood' 'helping' 'walked' 'squeaky' 'grab' 'discovered' 'funny'\n",
            " 'carrying' 'chose' 'cap' 'challenge' 'shame' 'perch' 'closer' 'faster'\n",
            " 'english' 'elastic' 'turning' 'plant' 'knowing' 'plush' 'jumping'\n",
            " 'preferred' 'hardly' 'smallest' 'ship' 'rarely' 'source' 'scratches'\n",
            " 'types' 'states' 'maltese' 'waterproof' 'trash' 'miracle' 'sweater'\n",
            " 'owned' 'beginning' 'tired' 'orange' 'width' 'directly' 'wife' 'crack'\n",
            " 'lift' 'complaints' 'comfortably' 'neighbors' 'seam' 'mice' 'general'\n",
            " 'sticky' 'list' 'shedding' 'section' 'bunny' 'boston' 'haired' 'release'\n",
            " 'squeeze' 'eater' 'feeling' 'shouldn' 'wild' 'sell' 'setup' 'walls'\n",
            " 'prime' 'according' 'miss' 'scratcher' 'vacuum' '70' 'paint' 'improved']\n",
            "['adjustment' 'tennis' 'duck' 'plush' 'accidentally' 'application'\n",
            " 'humans' 'sand' 'posts' 'proper' 'fleece' 'reviewer' 'noticeable' 'potty'\n",
            " 'schnauzer' 'accident' 'boston' 'list' 'liner' 'miniature' 'sale' 'trust'\n",
            " 'powerful' 'traveling' 'installation' 'rub' 'pair' 'dose' 'squirrels'\n",
            " 'buckle' 'pond' 'squeeze' 'walls' 'scratcher' 'sun' 'ways' 'odd' 'dig'\n",
            " 'younger' 'awkward' 'mistake' 'shiny' 'odors' 'thinks' 'upset' 'section'\n",
            " 'approved' 'died' 'tracking' 'cracked' 'preferred' 'removable' 'lack'\n",
            " 'tightly' 'ride' 'forget' 'shelf' 'miracle' 'filling' 'joint' 'ahead'\n",
            " 'washable' 'dropped' 'wont' 'pockets' 'bored' 'bunny' 'pictured' 'prices'\n",
            " 'challenge' 'world' 'strips' 'nylon' 'age' 'mention' 'personally'\n",
            " 'flexible' 'feline' 'pillow' 'cap' 'ask' 'yr' 'reduce' 'program' 'bunch'\n",
            " 'peanut' 'breeds' 'total' '45' 'tick' 'algae' 'carefully' 'liquid'\n",
            " 'success' 'listed' 'vs' 'trash' 'dead' 'road' 'crack']\n",
            "['prefers' 'throwing' 'beautifully' 'boys' 'returned' 'assembly' 'bully'\n",
            " 'fix' 'pocket' 'played' 'seriously' 'slowly' 'dinner' 'infection'\n",
            " 'sooner' 'undercoat' 'stuffed' 'china' 'track' 'rawhide' 'trainer' 'ride'\n",
            " 'upset' 'algae' 'rinse' 'yummy' 'climb' 'walked' 'website' 'nature'\n",
            " 'proof' 'bits' '75' 'humans' 'miniature' 'required' 'happened' 'closed'\n",
            " 'reviewers' 'avoid' 'fold' 'steel' 'mouse' 'video' 'somewhat' 'levels'\n",
            " 'tries' 'grocery' 'usual' 'cups' 'betta' 'belt' 'plant' 'straight'\n",
            " 'annoying' 'complete' 'pig' 'professional' 'younger' 'stuffing' 'breeze'\n",
            " 'appreciate' 'led' 'trash' 'picked' 'accurate' 'maintain' 'toss' 'scared'\n",
            " 'sell' 'round' 'pop' 'joints' 'relief' 'household' 'tends' 'strap'\n",
            " 'frequently' 'perch' 'protect' 'squeak' 'cuts' 'war' 'decent' 'carries'\n",
            " 'blade' 'sprayed' 'fabulous' 'directly' 'sister' 'setup' 'breaking'\n",
            " 'dane' 'surprise' 'peace' 'road' 'rope' 'promptly' 'hanging' 'apply']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}